# main_v2.py
import os
import operator
from typing import TypedDict, Annotated, List, Union
from langchain_openai import ChatOpenAI
from langchain_tavily import TavilySearch
from langchain_core.messages import BaseMessage, HumanMessage, AIMessage, SystemMessage
from langgraph.graph import StateGraph, END
from langgraph.checkpoint.memory import MemorySaver
from dotenv import load_dotenv
from llama_index.core import VectorStoreIndex, Document, StorageContext
from llama_index.vector_stores.postgres import PGVectorStore
from llama_index.embeddings.openai import OpenAIEmbedding
import sqlalchemy
import json
from tools import python_interpreter

# --- æ­¥éª¤ 1: åŠ è½½ API å¯†é’¥å’Œ LLM ---
load_dotenv()
llm = ChatOpenAI(model="gpt-4o", temperature=0)
web_search_tool = TavilySearch(max_results=3)

# --- æ­¥éª¤ 1.5: M4 - è®¾ç½®æ•°æ®åº“å’Œ LlamaIndex ---
DB_NAME = "astra_db"
# æ³¨æ„: Homebrew é»˜è®¤ä½¿ç”¨ä½ çš„ macOS ç”¨æˆ·å (maple) ä¸”æ— å¯†ç 
# (è¯·å°† "maple" æ›¿æ¢ä¸ºä½ çš„ macOS ç”¨æˆ·å, å¦‚æœä¸åŒçš„è¯)
DB_USER = "maple" 
DB_PASSWORD = "" # Homebrew é»˜è®¤
DB_HOST = "localhost"
DB_PORT = "5432"

# åˆ›å»º SQLAlchemy å¼•æ“
db_url = f"postgresql+psycopg2://{DB_USER}:{DB_PASSWORD}@{DB_HOST}:{DB_PORT}/{DB_NAME}"
engine = sqlalchemy.create_engine(db_url)

# åˆå§‹åŒ– LlamaIndex çš„ PGVectorStore
# "astra_collection" æ˜¯æˆ‘ä»¬ RAG æ•°æ®çš„è¡¨å
vector_store = PGVectorStore.from_params(
    database=DB_NAME,
    host=DB_HOST,
    port=DB_PORT,
    user=DB_USER,
    password=DB_PASSWORD,
    table_name="astra_collection",
    embed_dim=1536 # OpenAI åµŒå…¥çš„ç»´åº¦ (ada-002)
)

# å®šä¹‰åµŒå…¥æ¨¡å‹
embed_model = OpenAIEmbedding()

# åˆ›å»º LlamaIndex çš„"å­˜å‚¨ä¸Šä¸‹æ–‡"å’Œ"ç´¢å¼•"
storage_context = StorageContext.from_defaults(vector_store=vector_store)
index = VectorStoreIndex.from_documents(
    [], # å¯åŠ¨æ—¶, ç´¢å¼•æ˜¯ç©ºçš„
    storage_context=storage_context,
    embed_model=embed_model
)

# --- æ­¥éª¤ 2: M2 - å®šä¹‰æ–°çš„ "Agent çŠ¶æ€" ---
# è¿™æ¬¡, "å…¬æ–‡åŒ…" å˜å¾—æ›´å¤æ‚äº†
# å®ƒéœ€è¦è·Ÿè¸ª "è®¡åˆ’" å’Œ "æ­¥éª¤"
class AgentState(TypedDict):
    task: str                 # ç”¨æˆ·çš„åˆå§‹ä»»åŠ¡
    plan: str                 # è§„åˆ’å¸ˆç”Ÿæˆçš„è®¡åˆ’
    # research_data: List[str]  # ç ”ç©¶å‘˜æ‰¾åˆ°çš„æ•°æ®
    final_report: str         # å†™æ‰‹ç”Ÿæˆçš„æœ€ç»ˆæŠ¥å‘Š
    
    # "current_step" æ˜¯ M2 çš„å…³é”®, ç”¨äºè·¯ç”±
    # å®ƒè·Ÿè¸ªæˆ‘ä»¬ç°åœ¨åœ¨è®¡åˆ’çš„å“ªä¸€æ­¥
    current_step: str
    analysis_results: List[str]


# --- æ­¥éª¤ 3: M2 - å®šä¹‰æˆ‘ä»¬çš„ "ä¸“å®¶ Agent" èŠ‚ç‚¹ ---

# 3. è§„åˆ’å¸ˆ (Planner) èŠ‚ç‚¹ (O4 ç»ˆæç‰ˆ: éç”Ÿæˆå™¨)
async def planner_node(state: AgentState) -> dict: # (!! æ³¨æ„: è¿”å› dict, ä¸å†æ˜¯ generator)
    print("--- æ­£åœ¨è°ƒç”¨ [è§„åˆ’å¸ˆ (O4)] ---")
    task = state.get("task")
    
    prompt = f"""
    ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„é¡¹ç›®è§„åˆ’å¸ˆã€‚
    ä½ çš„ä»»åŠ¡æ˜¯ä¸ºç»™å®šçš„ [ä»»åŠ¡] åˆ¶å®šä¸€ä¸ªæ¸…æ™°ã€ç®€æ´ã€åˆ†æ­¥çš„è®¡åˆ’ã€‚
    [ä»»åŠ¡]: {task}
    
    å°†è®¡åˆ’åˆ†ä¸ºä»¥ä¸‹ä¸‰ä¸ªæ­¥éª¤ä¹‹ä¸€æˆ–å…¨éƒ¨:
    1. "Research": å¦‚æœä»»åŠ¡éœ€è¦ä»å¤–éƒ¨ä¸–ç•Œè·å–ä¿¡æ¯ (æœç´¢)ã€‚
    2. "Analyze": å¦‚æœä»»åŠ¡éœ€è¦æ•°å­¦è®¡ç®—ã€æ•°æ®å¤„ç†æˆ–ä»£ç æ‰§è¡Œã€‚
    3. "Write": ç¼–å†™æœ€ç»ˆæŠ¥å‘Šã€‚
    
    è¯·åªè¿”å›è®¡åˆ’æ­¥éª¤çš„åˆ—è¡¨, ä¾‹å¦‚:
    ["Research", "Analyze", "Write"]
    """
    
    messages = [HumanMessage(content=prompt)]
    
    print("--- [è§„åˆ’å¸ˆ O4] æ­£åœ¨æµå¼ç”Ÿæˆè®¡åˆ’... ---")
    
    # (å…³é”®) æˆ‘ä»¬åœ¨å†…éƒ¨æµå¼å¤„ç†, ä½†ä¸ "yield"
    full_plan_str = ""
    async for chunk in llm.astream(messages): # <--- astream_events ä¼š"ä¾¦å¬"åˆ°è¿™ä¸ª
        full_plan_str += chunk.content or ""
    
    print(f"--- [è§„åˆ’å¸ˆ O4] è®¡åˆ’ç”Ÿæˆå®Œæ¯•: {full_plan_str} ---")
    
    try:
        if "```json" in full_plan_str:
             full_plan_str = full_plan_str.split("```json")[1].split("```")[0]
        plan_steps = json.loads(full_plan_str.strip())
    except Exception as e:
        print(f"--- [è§„åˆ’å¸ˆ O4] è®¡åˆ’è§£æå¤±è´¥! {e} ---")
        plan_steps = ["Research", "Write"] # é™çº§
    
    # (!! å…³é”® !!) æˆ‘ä»¬ "return" æœ€ç»ˆç»“æœ, è€Œä¸æ˜¯ "yield"
    return {
        "plan": plan_steps,
        "current_step": plan_steps[0] if plan_steps else "END" 
    }

# 2. ç ”ç©¶å‘˜ (Researcher) èŠ‚ç‚¹ (ä¸ M1 ç›¸åŒ)
def researcher_node(state: AgentState) -> AgentState:
    print("--- æ­£åœ¨è°ƒç”¨ [ç ”ç©¶å‘˜ (M4)] ---")
    task = state.get("task")
    
    # 1. ä»ç„¶æ˜¯æœç´¢
    try:
        research_results = web_search_tool.invoke(task)
    except Exception as e:
        research_results = [f"æœç´¢å¤±è´¥: {e}"]
    
    # 2. M4 æ ¸å¿ƒ: "æ•°æ®æ‘„å…¥" (Ingestion)
    # æˆ‘ä»¬ä¸å†æŠŠæ•°æ®å¡è¿› state, è€Œæ˜¯å­˜å…¥ LlamaIndex (pgvector)
    
    print(f"--- [ç ”ç©¶å‘˜] æ‰¾åˆ°äº† {len(research_results)} æ¡ç»“æœã€‚æ­£åœ¨å­˜å…¥è®°å¿†... ---")
    
    # 2. [å…³é”®ä¿®æ”¹] æˆªæ–­è¿‡é•¿çš„å†…å®¹! (é˜²æ­¢çˆ† Token)
    # é™åˆ¶æ¯æ¡ç»“æœæœ€å¤š 4000 å­—ç¬¦ (çº¦ 1000-2000 tokens)
    MAX_CHARS = 4000
    # å°†åŸå§‹æœç´¢ç»“æœ (å­—ç¬¦ä¸²) è½¬æ¢ä¸º LlamaIndex "Document" å¯¹è±¡
    documents = []
    for result in research_results:
        # ç¡®ä¿ result æ˜¯å­—ç¬¦ä¸²
        content = str(result)
        # å¦‚æœå¤ªé•¿ï¼Œå°±æˆªæ–­
        if len(content) > MAX_CHARS:
            content = content[:MAX_CHARS] + "...(å·²æˆªæ–­)"
            
        documents.append(
            Document(
                text=content, 
                metadata={"task": task}
            )
        )
    
    # 3. æ’å…¥æ•°æ®åº“
    if documents:
        index.insert_nodes(documents)
    
    return {
        "current_step": "Analyze" # (æˆ–è€…æ ¹æ®ä½ çš„è·¯ç”±é€»è¾‘)
    }

# 4. åˆ†æå¸ˆ (Analyst) èŠ‚ç‚¹ (M6 æ–°å¢)
async def analyst_node(state: AgentState) -> dict:
    print("--- æ­£åœ¨è°ƒç”¨ [åˆ†æå¸ˆ (M6)] ---")
    task = state.get("task")
    query_engine = index.as_query_engine(similarity_top_k=3)
    rag_context = await query_engine.aquery(task)
    
    # è¿™é‡Œçš„ Prompt æ—¨åœ¨è®© LLM ç”Ÿæˆ Python ä»£ç 
    prompt = f"""
    ä½ æ˜¯ä¸€ä¸ªç²¾é€š Python çš„æ•°æ®åˆ†æå¸ˆã€‚
    ä½ çš„ä»»åŠ¡æ˜¯ç¼–å†™ Python ä»£ç æ¥è§£å†³ä»¥ä¸‹é—®é¢˜ã€‚
    
    [ä»»åŠ¡]: {task}
    
    [å‚è€ƒæ•°æ®/èƒŒæ™¯ä¿¡æ¯]:
    {rag_context}
    
    è¯·éµå¾ªä»¥ä¸‹æ­¥éª¤:
    1. **ä»”ç»†é˜…è¯» [å‚è€ƒæ•°æ®]**ã€‚å¦‚æœé‡Œé¢åŒ…å«äº†å…·ä½“çš„æ•°å€¼ï¼ˆä¾‹å¦‚å¹´ä»½ã€é‡‘é¢ã€å•ä½ï¼‰ï¼Œ**å¿…é¡»**ä½¿ç”¨è¿™äº›çœŸå®æ•°æ®æ¥æ„å»ºä½ çš„ä»£ç ä¸­çš„å˜é‡ã€‚
    2. å¦‚æœ [å‚è€ƒæ•°æ®] ä¸­æ²¡æœ‰å…·ä½“æ•°å€¼ï¼Œè¯·å°è¯•æ ¹æ®ä½ çš„çŸ¥è¯†è¿›è¡Œ**åˆç†çš„ä¼°ç®—**ï¼ˆä¾‹å¦‚åŒ—æ¬§ç”µåŠ›æ”¶ç›Šé€šå¸¸åœ¨ 20ä¸‡æ¬§å…ƒ/MW å·¦å³ï¼Œè€Œä¸æ˜¯å‡ åæ¬§å…ƒï¼‰ï¼Œå¹¶åœ¨ä»£ç æ³¨é‡Šä¸­è¯´æ˜è¿™æ˜¯ä¼°ç®—å€¼ã€‚
    3. ç¼–å†™ Python ä»£ç ï¼Œé€šè¿‡ Docker æ²™ç®±æ‰§è¡Œã€‚
    4. **ç»˜å›¾ä¿®æ­£**: 
       - ä½¿ç”¨ `sns.lineplot` æ—¶ï¼Œå¦‚æœåªç”»ä¸€æ¡çº¿ï¼Œ**ä¸è¦**è®¾ç½® `palette` å‚æ•°ï¼Œè¿™ä¼šå¯¼è‡´ UserWarningã€‚å¯ä»¥ç›´æ¥æŒ‡å®š `color='blue'`ã€‚
       - åŠ¡å¿…ä¿å­˜å›¾ç‰‡åˆ° `/app/output.png`ã€‚
    5. åŠ¡å¿…ä½¿ç”¨ print() è¾“å‡ºæœ€ç»ˆçš„å…³é”®æ•°æ®ã€‚
    """
    
    # æˆ‘ä»¬ç»‘å®šå·¥å…·! 
    # è¿™æ˜¯ä¸€ä¸ªé«˜çº§æŠ€å·§: Bind Tools
    analyst_llm = llm.bind_tools([python_interpreter])
    
    messages = [HumanMessage(content=prompt)]
    
    print("--- [åˆ†æå¸ˆ] æ­£åœ¨ç¼–å†™å¹¶æ‰§è¡Œä»£ç ... ---")
    
    # è°ƒç”¨ LLM, å®ƒä¼šå†³å®šæ˜¯å¦è°ƒç”¨å·¥å…·
    response = await analyst_llm.ainvoke(messages)
    
    analysis_output = "åˆ†æå¸ˆæœªæ‰§è¡Œä»£ç ã€‚"
    
    # æ£€æŸ¥ LLM æ˜¯å¦æƒ³è¦è°ƒç”¨å·¥å…·
    if response.tool_calls:
        for tool_call in response.tool_calls:
            if tool_call["name"] == "python_interpreter":
                code = tool_call["args"]["code"]
                print(f"--- [åˆ†æå¸ˆ] æ­£åœ¨æ²™ç®±ä¸­è¿è¡Œ: \n{code} ---")
                
                # æ‰§è¡Œå·¥å…· (Docker)
                tool_result = python_interpreter.invoke(code)
                
                print(f"--- [åˆ†æå¸ˆ] æ²™ç®±è¿”å›: \n{tool_result} ---")
                analysis_output = tool_result
    else:
        # å¦‚æœ LLM ç›´æ¥è¯´è¯äº† (æ²¡è°ƒå·¥å…·)ï¼Œæˆ‘ä»¬å°±ç”¨å®ƒçš„è¯
        analysis_output = response.content

    return {
        "analysis_results": [analysis_output], # å­˜å…¥çŠ¶æ€
        "current_step": "Write" # åˆ†æå®Œé€šå¸¸å»å†™ä½œ (æˆ–ç”± Supervisor å†³å®š)
    }

# 5. å†™æ‰‹ (Writer) èŠ‚ç‚¹ (O4 ç»ˆæç‰ˆ: éç”Ÿæˆå™¨)
async def writer_node(state: AgentState) -> dict: # (!! æ³¨æ„: è¿”å› dict)
    print("--- æ­£åœ¨è°ƒç”¨ [å†™æ‰‹ (O4)] ---")
    task = state.get("task")
    
    print("--- [å†™æ‰‹ O4] æ­£åœ¨ä» pgvector å¼‚æ­¥æ£€ç´¢... ---")
    query_engine = index.as_query_engine(similarity_top_k=3)
    rag_context = await query_engine.aquery(task) # å¼‚æ­¥ RAG
    # è·å–åˆ†æç»“æœ
    analysis_results = state.get("analysis_results", [])
    
    print("--- [å†™æ‰‹ O4] è®°å¿†æ£€ç´¢å®Œæ¯• ---")
    
    prompt = f"""
    ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ç§‘æŠ€æŠ¥å‘Šå†™æ‰‹ã€‚
    æ ¹æ® [ä»»åŠ¡]ã€[RAG ä¸Šä¸‹æ–‡] å’Œ [æ•°æ®åˆ†æç»“æœ], æ’°å†™ä¸€ä»½ä¸“ä¸šçš„æ€»ç»“æŠ¥å‘Šã€‚
    
    [ä»»åŠ¡]: {task}
    [RAG ä¸Šä¸‹æ–‡]: {rag_context}
    [æ•°æ®åˆ†æç»“æœ]: {analysis_results}
    """
    
    messages = [HumanMessage(content=prompt)]
    
    print("--- [å†™æ‰‹ O4] æ­£åœ¨æµå¼ç”ŸæˆæŠ¥å‘Š... ---")
    
    full_report = ""
    
    # (å…³é”®) æˆ‘ä»¬åœ¨å†…éƒ¨æµå¼å¤„ç†, astream_events ä¼š"ä¾¦å¬"åˆ°è¿™ä¸ª
    async for chunk in llm.astream(messages):
        full_report += chunk.content or ""

    print("--- [å†™æ‰‹ O4] æŠ¥å‘Šç”Ÿæˆå®Œæ¯• ---")
    
    # (!! å…³é”® !!) æˆ‘ä»¬ "return" æœ€ç»ˆç»“æœ
    return {
        "final_report": full_report, 
        "current_step": "END"
    }

# --- æ­¥éª¤ 4: M2 - "è€æ¿" (Supervisor) çš„è·¯ç”±é€»è¾‘ ---
# è¿™å°±æ˜¯ "æ¡ä»¶è¾¹" (Conditional Edge) çš„æ ¸å¿ƒ!

def supervisor_router(state: AgentState) -> str:
    """
    è¿™æ˜¯æˆ‘ä»¬çš„"è€æ¿"(Supervisor)ã€‚
    å®ƒæ£€æŸ¥ "current_step" å­—æ®µ, ç„¶åå†³å®šä¸‹ä¸€æ­¥å»å“ªä¸ªèŠ‚ç‚¹ã€‚
    """
    print(f"--- [ä¸»ç®¡] æ­£åœ¨è·¯ç”±: {state.get('current_step')} ---")
    
    current_step = state.get("current_step")
    
    if current_step == "Research":
        return "Researcher"
    elif current_step == "Analyze": # <--- æ–°å¢
        return "Analyst"
    elif current_step == "Write":
        return "Writer"
    elif current_step == "END":
        return "END"

# --- æ­¥éª¤ 5: æ„å»º M2 çš„ "æ™ºèƒ½å›¾" ---
workflow = StateGraph(AgentState)

# 1. æ·»åŠ æ‰€æœ‰èŠ‚ç‚¹
workflow.add_node("Planner", planner_node)
workflow.add_node("Researcher", researcher_node)
workflow.add_node("Analyst", analyst_node)
workflow.add_node("Writer", writer_node)

# 2. è®¾ç½®"å…¥å£"
workflow.set_entry_point("Planner")

# 3. æ·»åŠ "æ¡ä»¶è·¯ç”±"
# è¿™æ˜¯ M2 çš„é­”æ³•!
# æˆ‘ä»¬æ·»åŠ ä¸€ä¸ª"æ¡ä»¶è¾¹", ä» "Planner" èŠ‚ç‚¹å‡ºå‘
# å®ƒä¼šå»è°ƒç”¨ `supervisor_router` å‡½æ•°
# `supervisor_router` ä¼šè¿”å›ä¸€ä¸ªå­—ç¬¦ä¸² ("Researcher", "Writer" æˆ– END)
# ç„¶åå›¾ä¼šæ ¹æ®è¿™ä¸ªå­—ç¬¦ä¸², è·³è½¬åˆ°å¯¹åº”çš„èŠ‚ç‚¹
workflow.add_conditional_edges(
    "Planner",         # "è§„åˆ’å¸ˆ" è¿è¡Œå®Œæ¯•å...
    supervisor_router, # ...è°ƒç”¨"ä¸»ç®¡"æ¥å†³å®šä¸‹ä¸€æ­¥
    {
        "Researcher": "Researcher", # å¦‚æœä¸»ç®¡è¯´"Research", å°±å»"ç ”ç©¶å‘˜"
        "Analyst": "Analyst",
        "Writer": "Writer",         # å¦‚æœä¸»ç®¡è¯´"Write", å°±å»"å†™æ‰‹"
        "END": END                  # å¦‚æœä¸»ç®¡è¯´"END", å°±ç»“æŸ
    }
)

# ä¸º Analyst æ·»åŠ è·¯ç”± (åˆ†æå®Œå»æ‰¾ä¸»ç®¡ï¼Œæˆ–è€…åƒæˆ‘ä»¬è¿™é‡Œç®€åŒ–çš„: é»˜è®¤å» Write)
# ä¸ºäº†æ›´æ™ºèƒ½ï¼Œæˆ‘ä»¬è¿˜æ˜¯ç”¨ supervisor_router
workflow.add_conditional_edges(
    "Analyst",
    supervisor_router,
    {
        "Writer": "Writer", # é€šå¸¸åˆ†æå®Œå°±å†™
        "END": END
    }
)

# 4. "ç ”ç©¶å‘˜" å’Œ "å†™æ‰‹" è·‘å®Œå, æ€ä¹ˆåŠ?
# ç­”æ¡ˆæ˜¯: ä»–ä»¬ä¹Ÿåº”è¯¥å›å»æ‰¾"ä¸»ç®¡"æ±‡æŠ¥!
# (æ³¨æ„: åœ¨è¿™ä¸ªç®€å• M2 ä¸­, æˆ‘ä»¬ç®€åŒ–äº†, è®©èŠ‚ç‚¹è‡ªå·±å†³å®šä¸‹ä¸€æ­¥)
# (åœ¨ä¸€ä¸ªæ›´é«˜çº§çš„ M3 ä¸­, Supervisor åº”è¯¥åœ¨æ¯ä¸€æ­¥éƒ½ä»‹å…¥)

# ä¸ºäº†ç®€åŒ– M2, æˆ‘ä»¬è®© "Researcher" è·‘å®Œåæ€»æ˜¯å» "Writer"
# (åœ¨ M1 ä¸­æˆ‘ä»¬ç”¨ add_edge, åœ¨ M2 ä¸­æˆ‘ä»¬è®©èŠ‚ç‚¹è‡ªå·±æ›´æ–° current_step)
# æˆ‘ä»¬éœ€è¦ä¸€ä¸ª"é€šç”¨"çš„è·¯ç”±ç‚¹

# è®©æˆ‘ä»¬é‡æ„ä¸€ä¸‹, è¿™æ‰æ˜¯æ­£ç¡® M2 ç»“æ„:
# "ä¸»ç®¡" åº”è¯¥åœ¨æ¯ä¸€æ­¥ä¹‹åéƒ½è¢«è°ƒç”¨

# --- æ­¥éª¤ 5 (é‡æ„ - æ­£ç¡®çš„ M2 ç»“æ„) ---
workflow = StateGraph(AgentState)

# 1. æ·»åŠ èŠ‚ç‚¹
workflow.add_node("Planner", planner_node)
workflow.add_node("Researcher", researcher_node)
workflow.add_node("Writer", writer_node)

# 2. å…¥å£
workflow.set_entry_point("Planner")

# 3. å®šä¹‰"é€šç”¨"è·¯ç”±
# (è¿™æ˜¯ä¸€ä¸ªæ›´é«˜çº§ã€æ›´åƒ Manus çš„ç»“æ„)
# æˆ‘ä»¬è®© "Planner", "Researcher", "Writer" è·‘å®Œå
# *å…¨éƒ¨* å›åˆ° "Supervisor" è¿™é‡Œ, ç”± "Supervisor" å†³å®šä¸‹ä¸€æ­¥

# (ä¸ºäº†è®©è¿™ä¸ª M2 ä¿æŒç®€å•å’Œå¯è¿è¡Œ, æˆ‘ä»¬å…ˆç”¨ V1 çš„é€»è¾‘)
# (V1 é€»è¾‘: è§„åˆ’ -> [è·¯ç”±] -> ç ”ç©¶ -> å†™ä½œ -> [è·¯ç”±] -> ç»“æŸ)

# --- æ­¥éª¤ 5 (M2 - å¯è¿è¡Œçš„æœ€ç»ˆç‰ˆ) ---
workflow = StateGraph(AgentState)

workflow.add_node("Planner", planner_node)
workflow.add_node("Researcher", researcher_node)
workflow.add_node("Analyst", analyst_node)
workflow.add_node("Writer", writer_node)

workflow.set_entry_point("Planner")

# 1. è§„åˆ’å¸ˆ (Planner) è·‘å®Œ, å»æ‰¾ ä¸»ç®¡ (Supervisor)
workflow.add_conditional_edges(
    "Planner",
    supervisor_router,
    {"Researcher": "Researcher", "Analyst": "Analyst", "Writer": "Writer", "END": END}
)

# 2. ç ”ç©¶å‘˜ (Researcher) è·‘å®Œ, ä¹Ÿå»æ‰¾ ä¸»ç®¡
workflow.add_conditional_edges(
    "Researcher",
    supervisor_router,
    {"Analyst": "Analyst", "Writer": "Writer", "END": END} # ç ”ç©¶å®Œ, åªå¯èƒ½å»å†™ä½œæˆ–ç»“æŸ
)

# 3. å†™æ‰‹ (Writer) è·‘å®Œ, ä¹Ÿå»æ‰¾ ä¸»ç®¡
workflow.add_conditional_edges(
    "Writer",
    supervisor_router,
    {"END": END} # å†™å®Œ, åªèƒ½ç»“æŸ
)

# 4. ç¼–è¯‘
memory = MemorySaver()
app = workflow.compile(
    checkpointer=memory,
    interrupt_after=["Planner"]
)

# --- æ­¥éª¤ 6: è¿è¡Œ M2 Agent ---
if __name__ == "__main__":
    print("ğŸš€ Astra Agent å·²å¯åŠ¨... (M2 ç‰ˆæœ¬: æ™ºèƒ½è·¯ç”±)")
    
    session_config = {"configurable": {"thread_id": "session-2"}}
    
    task = "è°ƒç ” 2025 å¹´ AI Agent å¸‚åœºçš„æœ€æ–°è¶‹åŠ¿, ç‰¹åˆ«æ˜¯å…³äº Manus, OpenAI å’Œ Google çš„"
    
    print(f"--- ä»»åŠ¡: {task} ---")
    
    # ä½¿ç”¨ .stream() æ¥"ç›´æ’­" Agent çš„æ¯ä¸€æ­¥
    for step in app.stream({"task": task}, config=session_config):
        # stream() ä¼šè¿”å›æ¯ä¸€æ­¥çš„èŠ‚ç‚¹åç§°å’Œå…¶è¾“å‡º
        node_name = list(step.keys())[0]
        node_output = step[node_name]
        print(f"--- [æµ] èŠ‚ç‚¹: {node_name} ---")
        # æ‰“å°çŠ¶æ€çš„"å¢é‡"
        print(f"--- [æµ] è¾“å‡º: {node_output} ---")

    # (æˆ‘ä»¬ä¹Ÿå¯ä»¥ç”¨ .invoke() ä¸€æ¬¡æ€§è¿è¡Œåˆ°åº•)
    # final_state = app.invoke({"task": task}, config=session_config)
    # print("\n========= [æœ€ç»ˆæŠ¥å‘Š] =========")
    # print(final_state.get("final_report"))

