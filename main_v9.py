import os
import operator
from typing import TypedDict, Annotated, List, Union
from langchain_openai import ChatOpenAI
from langchain_tavily import TavilySearch
from langchain_core.messages import BaseMessage, HumanMessage
from langgraph.graph import StateGraph, END
from langgraph.checkpoint.memory import MemorySaver
from dotenv import load_dotenv
from llama_index.core import VectorStoreIndex, Document, StorageContext
from llama_index.vector_stores.postgres import PGVectorStore
from llama_index.embeddings.openai import OpenAIEmbedding
import sqlalchemy
import json
from tools import python_interpreter

# --- 1. é…ç½®ä¸åˆå§‹åŒ– ---
load_dotenv()
llm = ChatOpenAI(model="gpt-4o", temperature=0)
web_search_tool = TavilySearch(max_results=3)

DB_NAME = "astra_db"
DB_USER = "maple" # è¯·ç¡®è®¤ç”¨æˆ·å
DB_PASSWORD = ""
DB_HOST = "localhost"
DB_PORT = "5432"

db_url = f"postgresql+psycopg2://{DB_USER}:{DB_PASSWORD}@{DB_HOST}:{DB_PORT}/{DB_NAME}"
engine = sqlalchemy.create_engine(db_url)

vector_store = PGVectorStore.from_params(
    database=DB_NAME, host=DB_HOST, port=DB_PORT, user=DB_USER, password=DB_PASSWORD,
    table_name="astra_collection", embed_dim=1536
)
embed_model = OpenAIEmbedding()
storage_context = StorageContext.from_defaults(vector_store=vector_store)
index = VectorStoreIndex.from_documents([], storage_context=storage_context, embed_model=embed_model)

# --- 2. çŠ¶æ€å®šä¹‰ ---
class AgentState(TypedDict):
    task: str
    plan: List[str] # æ˜ç¡®ç±»å‹ä¸º List
    final_report: str
    current_step: str
    analysis_results: Annotated[List[str], operator.add] # å†å²ç´¯ç§¯
    retry_count: int
    image_data: str
    # [æ–°å¢] æ˜¯å¦éœ€è¦äººå·¥å®¡æ‰¹
    needs_review: bool

# --- 3. è¾…åŠ©å‡½æ•°: åŠ¨æ€è®¡ç®—ä¸‹ä¸€æ­¥ ---
def get_next_step_name(plan: List[str], current_step_name: str) -> str:
    """æ ¹æ®å½“å‰å®Œæˆçš„æ­¥éª¤ï¼Œåœ¨è®¡åˆ’åˆ—è¡¨ä¸­æ‰¾åˆ°ä¸‹ä¸€æ­¥"""
    try:
        current_index = plan.index(current_step_name)
        if current_index + 1 < len(plan):
            return plan[current_index + 1]
        else:
            return "END"
    except ValueError:
        return "END"

# --- 4. èŠ‚ç‚¹å®šä¹‰ ---

# 1. è§„åˆ’å¸ˆ (Planner)
async def planner_node(state: AgentState) -> dict:
    print("--- [è§„åˆ’å¸ˆ] å¼€å§‹å·¥ä½œ ---")
    task = state.get("task")
    
    # [ä¼˜åŒ–] å‘Šè¯‰ Planner "Write" æ˜¯å¯é€‰çš„
    prompt = f"""
    ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„é¡¹ç›®è§„åˆ’å¸ˆã€‚ä»»åŠ¡: {task}
    è¯·åˆ¶å®šæ­¥éª¤è®¡åˆ’ï¼Œä»ä»¥ä¸‹é€‰æ‹©:
    1. "Research": éœ€è¦å¤–éƒ¨ä¿¡æ¯ã€‚
    2. "Analyze": éœ€è¦è®¡ç®—ã€ä»£ç æ‰§è¡Œæˆ–ç”Ÿæˆæ–‡ä»¶ã€‚
    3. "Write": éœ€è¦å†™ä¸€ä»½è¯¦ç»†çš„æ–‡å­—æ€»ç»“æŠ¥å‘Šã€‚
    
    ã€å…³é”®è§„åˆ™ã€‘:
    - å¦‚æœä»»åŠ¡åªæ˜¯è¦æ±‚ç›´æ¥çš„ç­”æ¡ˆã€è®¡ç®—ç»“æœæˆ–ç”Ÿæˆç‰¹å®šæ–‡ä»¶(å¦‚"ç”Ÿæˆ5ä¸ªåå­—", "ç”»å¼ å›¾")ï¼Œ**ä¸è¦**åŒ…å« "Write"ã€‚
    - åªæœ‰å½“ç”¨æˆ·æ˜ç¡®éœ€è¦"æŠ¥å‘Š"ã€"æ€»ç»“"æˆ–ä»»åŠ¡å¾ˆå¤æ‚éœ€è¦è§£é‡Šæ—¶ï¼Œæ‰åŒ…å« "Write"ã€‚

    åŒæ—¶ï¼Œè¯·åˆ¤æ–­è¯¥ä»»åŠ¡æ˜¯å¦éœ€è¦ã€ç”¨æˆ·å®¡æ‰¹ã€‘(needs_review):
    - å¦‚æœä»»åŠ¡æœ‰é£é™©ï¼ˆå¦‚åˆ é™¤æ–‡ä»¶ï¼‰ã€éå¸¸å¤æ‚ã€æˆ–è€…æŒ‡ä»¤æ¨¡ç³Šä¸ç¡®å®šï¼Œè¯·è®¾ä¸º trueã€‚
    - å¦‚æœä»»åŠ¡å¾ˆç®€å•ã€æ˜ç¡®ï¼ˆå¦‚"ç”»ä¸ªæ­£å¼¦å‡½æ•°å›¾"ã€"æœç´¢ä»Šå¤©çš„æ±‡ç‡"ï¼‰ï¼Œè¯·è®¾ä¸º false (è‡ªåŠ¨æ‰§è¡Œ)ã€‚
    
    ã€é‡è¦ã€‘è¯·ä¸¥æ ¼è¿”å›ä»¥ä¸‹ JSON æ ¼å¼ï¼ˆä¸è¦ Markdownï¼Œçº¯ JSONï¼‰:
    {{
        "plan": ["Research", "Analyze"],
        "needs_review": false
    }}
    """
    messages = [HumanMessage(content=prompt)]
    
    full_plan_str = ""
    async for chunk in llm.astream(messages):
        full_plan_str += chunk.content or ""
    
    try:
        # æ¸…ç† Markdown æ ‡è®°
        clean_str = full_plan_str.replace("```json", "").replace("```", "").strip()
        result_data = json.loads(clean_str)
        
        plan_steps = result_data.get("plan", ["Research", "Write"])
        needs_review = result_data.get("needs_review", False)
        
    except Exception as e:
        print(f"è®¡åˆ’è§£æå¤±è´¥ï¼Œé™çº§å¤„ç†: {e}")
        plan_steps = ["Research", "Write"]
        needs_review = True # è§£æå¤±è´¥æ—¶ï¼Œä¸ºäº†å®‰å…¨ï¼Œé»˜è®¤å¼€å¯å®¡æ‰¹
    
    # åˆå§‹æ­¥éª¤
    first_step = plan_steps[0] if plan_steps else "END"
    return {"plan": plan_steps, "current_step": first_step, "needs_review": needs_review}

# 2. ç ”ç©¶å‘˜ (Researcher)
def researcher_node(state: AgentState) -> dict:
    print("--- [ç ”ç©¶å‘˜] å¼€å§‹æœç´¢ ---")
    task = state.get("task")
    try:
        research_results = web_search_tool.invoke(task)
    except Exception as e:
        research_results = [f"æœç´¢å¤±è´¥: {e}"]
    
    MAX_CHARS = 4000
    documents = []
    for result in research_results:
        content = str(result)
        if len(content) > MAX_CHARS: content = content[:MAX_CHARS] + "..."
        documents.append(Document(text=content, metadata={"task": task}))
    
    if documents:
        index.insert_nodes(documents)
    
    # [ä¼˜åŒ–] è‡ªåŠ¨è®¡ç®—ä¸‹ä¸€æ­¥
    plan = state.get("plan", [])
    next_step = get_next_step_name(plan, "Research")
    return {"current_step": next_step}

# 3. åˆ†æå¸ˆ (Analyst)
async def analyst_node(state: AgentState) -> dict:
    print("--- [åˆ†æå¸ˆ] å¼€å§‹åˆ†æ ---")
    task = state.get("task")
    image_data = state.get("image_data") # è·å–å›¾ç‰‡
    previous_results = state.get("analysis_results", [])
    retry_count = state.get("retry_count", 0)
    
    query_engine = index.as_query_engine(similarity_top_k=3)
    rag_context = await query_engine.aquery(task)
    
    prompt = f"""
      ä½ æ˜¯ä¸€ä¸ªç²¾é€š Python çš„æ•°æ®åˆ†æå¸ˆã€‚ä»»åŠ¡: {task}
      èƒŒæ™¯: {rag_context}

      ã€ä»£ç æ‰§è¡Œä¸é˜²å¹»è§‰åè®®ã€‘(CRITICAL):
      1. **Fact Check**: å¦‚æœä½ æ²¡æœ‰ç¼–å†™ä»£ç è°ƒç”¨ `python_interpreter`ï¼Œ**ç»å¯¹ç¦æ­¢**åœ¨å›å¤ä¸­å£°ç§°â€œæ–‡ä»¶å·²ä¿å­˜â€æˆ–æåŠ `/app/output.png`ã€‚
      2. åªæœ‰å½“ä½ ç”Ÿæˆçš„ Python ä»£ç ä¸­ç¡®å®åŒ…å« `plt.savefig('/app/output.png')` æ—¶ï¼Œæ‰å…è®¸åœ¨ä»£ç æ³¨é‡Šæˆ–æœ€ç»ˆæ€»ç»“ä¸­æåŠè¯¥æ–‡ä»¶ã€‚
      3. å¦‚æœä»»åŠ¡ä¸éœ€è¦ä»£ç ï¼ˆä¾‹å¦‚çº¯é€»è¾‘åˆ†æï¼‰ï¼Œè¯·ç›´æ¥ç»™å‡ºæ–‡å­—ç»“è®ºï¼Œä¸è¦å‡è£…è¿è¡Œäº†ä»£ç ã€‚
      
      ã€ä»£ç æ‰§è¡Œè¦æ±‚ã€‘:
      1. åŠ¡å¿…ä½¿ç”¨ print() è¾“å‡ºæœ€ç»ˆç»“æœã€‚
      2. ä»…åœ¨éœ€è¦æ—¶ç»˜å›¾ (/app/output.png)ã€‚
      3. **ä¸è¦**åœ¨ä»£ç ä¸­è®¾ç½®ç»˜å›¾é£æ ¼ (å¦‚ `sns.set_theme`)ï¼Œç¯å¢ƒå·²é¢„ç½®äº†æ”¯æŒä¸­æ–‡çš„å­¦æœ¯é£æ ¼é…ç½®ã€‚ç›´æ¥ç”»å›¾å³å¯ã€‚
      4. ä¼˜å…ˆä½¿ç”¨ **Seaborn** (`sns`) ç»˜å›¾ï¼Œå…¶æ¬¡æ˜¯ Matplotlib (`plt`)ã€‚
      
      ã€é€šç”¨ç¾å­¦ä¸é…è‰²è§„èŒƒã€‘(å¿…é¡»ä¸¥æ ¼éµå®ˆ):
      1. **ä¸¥ç¦ç¡¬ç¼–ç é¢œè‰²**: ç¦æ­¢å‡ºç° `color=['red', 'blue']` æˆ– `c='k'` è¿™ç§ä»£ç ã€‚ç¯å¢ƒå·²é¢„ç½®äº†ä¼˜é›…çš„ `custom_colors`ï¼Œè¯·åˆ©ç”¨å®ƒã€‚
      
      2. **åˆ†ç±»å›¾è¡¨ (æŸ±çŠ¶å›¾ bar / æ•£ç‚¹å›¾ scatter / ç®±çº¿å›¾ box / å°æç´å›¾ violin)**:
         - **è§„åˆ™**: å¿…é¡»é€šè¿‡ `hue` å‚æ•°æ¿€æ´»è‡ªåŠ¨é…è‰²ã€‚
         - **å†™æ³•**: `sns.barplot(x=vars, y=vals, hue=vars, legend=False)`
         - **åŸç†**: å¦‚æœä¸åŠ  `hue`ï¼ŒSeaborn é»˜è®¤åªç”¨ä¸€ç§é¢œè‰²ï¼›åŠ ä¸Š `hue` æ‰ä¼šæŒ‰ç±»åˆ«å¾ªç¯ä½¿ç”¨å…¨å±€è‰²ç›˜ã€‚
         
      3. **é¥¼å›¾ (Pie Chart)**:
         - **è§„åˆ™**: Matplotlib çš„é¥¼å›¾ä¸ä¼šè‡ªåŠ¨é€šè¿‡ hue å–è‰²ï¼Œå¿…é¡»æ‰‹åŠ¨è°ƒç”¨å…¨å±€è‰²ç›˜ã€‚
         - **å†™æ³•**: `plt.pie(values, labels=labels, colors=sns.color_palette(), autopct='%1.1f%%')`
         - **æ³¨æ„**: å¿…é¡»ä¼  `colors=sns.color_palette()`ï¼Œå¦åˆ™å®ƒä¼šå˜å›ä¸‘é™‹çš„é»˜è®¤è“/æ©™è‰²ã€‚
         
      4. **æŠ˜çº¿å›¾ (Line Chart)**:
         - **è§„åˆ™**: å¤šæ¡çº¿è¯·ç”¨ `hue` åˆ†ç»„ï¼›å•æ¡çº¿ä¿æŒé»˜è®¤é¢œè‰²å³å¯ï¼ˆä¼šè‡ªåŠ¨ä½¿ç”¨è‰²ç›˜çš„ç¬¬ä¸€ä¸ªä¸»è‰²ï¼Œéå¸¸åè°ƒï¼‰ã€‚
         
      5. **çƒ­åŠ›å›¾ (Heatmap)**:
         - **è§„åˆ™**: ç¦æ­¢ä½¿ç”¨é»˜è®¤é…è‰²ã€‚
         - **æ¨è**: `cmap='YlGnBu'` (æ¸…æ–°è“ç»¿ï¼Œé€‚åˆä¸€èˆ¬æ•°æ®) æˆ– `cmap='RdBu_r'` (çº¢è“å‘æ•£ï¼Œé€‚åˆæœ‰æ­£è´Ÿå¯¹æ¯”çš„æ•°æ®)ã€‚
         - **å†™æ³•**: `sns.heatmap(data, cmap='YlGnBu', annot=True)`
    """
    if retry_count > 0 and previous_results:
        prompt += f"\nã€ä¿®å¤é”™è¯¯ã€‘ä¸Šæ¬¡å¤±è´¥: {previous_results[-1]}\nè¯·ä¿®æ­£ä»£ç ã€‚"
    
    # [M11 æ ¸å¿ƒé€»è¾‘] æ„é€ å¤šæ¨¡æ€æ¶ˆæ¯
    if image_data:
        print("--- [åˆ†æå¸ˆ] æ”¶åˆ°å›¾ç‰‡, æ­£åœ¨è¿›è¡Œè§†è§‰åˆ†æ... ---")
        # å¦‚æœæœ‰å›¾ç‰‡ï¼Œcontent æ˜¯ä¸€ä¸ªåˆ—è¡¨
        message_content = [
            {"type": "text", "text": prompt},
            {
                "type": "image_url", 
                "image_url": {"url": f"data:image/jpeg;base64,{image_data}"}
            }
        ]
    else:
        # å¦‚æœæ²¡å›¾ç‰‡ï¼Œcontent å°±æ˜¯æ™®é€šå­—ç¬¦ä¸²
        message_content = prompt
    
    analyst_llm = llm.bind_tools([python_interpreter])
    messages = [HumanMessage(content=message_content)]
    
    response = await analyst_llm.ainvoke(messages)
    analysis_output = response.content

    # æ£€æŸ¥æ˜¯å¦å‘ç”Ÿäº†â€œæ²¡è°ƒå·¥å…·å´å£°ç§°æœ‰æ–‡ä»¶â€çš„æƒ…å†µ
    if not response.tool_calls and "/app/output.png" in str(analysis_output):
        print("--- [ç³»ç»Ÿçº é”™] æ£€æµ‹åˆ° Analyst å¹»è§‰ (æœªæ‰§è¡Œä»£ç å´å£°ç§°æœ‰å›¾)ï¼Œæ­£åœ¨ä¿®æ­£... ---")
        analysis_output = "[ç³»ç»Ÿæç¤º]: åˆ†æå¸ˆæœªæ‰§è¡Œä»»ä½•ä»£ç ï¼Œå› æ­¤æ²¡æœ‰ç”Ÿæˆå›¾è¡¨ã€‚è¯·å¿½ç•¥å…³äº /app/output.png çš„æè¿°ï¼Œä»…å‚è€ƒæ–‡å­—åˆ†æã€‚"
    
    if response.tool_calls:
        for tool_call in response.tool_calls:
            if tool_call["name"] == "python_interpreter":
                code = tool_call["args"]["code"]
                print(f"--- [åˆ†æå¸ˆ] æ‰§è¡Œä»£ç ... ---")
                analysis_output = python_interpreter.invoke(code)

    current_retry = state.get("retry_count", 0)
    
    # [ä¼˜åŒ–] è‡ªåŠ¨è®¡ç®—ä¸‹ä¸€æ­¥
    plan = state.get("plan", [])
    next_step = get_next_step_name(plan, "Analyze")
    
    return {
        "analysis_results": [analysis_output], 
        "retry_count": current_retry + 1,
        "current_step": next_step # æ›´æ–°ä¸ºä¸‹ä¸€æ­¥ (å¯èƒ½æ˜¯ Write æˆ– END)
    }

# 4. å†™æ‰‹ (Writer)
async def writer_node(state: AgentState) -> dict:
    print("--- [å†™æ‰‹] å¼€å§‹å†™ä½œ ---")
    task = state.get("task")
    query_engine = index.as_query_engine(similarity_top_k=3)
    rag_context = await query_engine.aquery(task)
    analysis_results = state.get("analysis_results", [])
    
    prompt = f"""
    ä¸“ä¸šå†™æ‰‹ã€‚ä»»åŠ¡: {task}
    ä¸Šä¸‹æ–‡: {rag_context}
    æ•°æ®åˆ†æ: {analysis_results}
    è¯·æ’°å†™æŠ¥å‘Šã€‚
    """
    messages = [HumanMessage(content=prompt)]
    
    full_report = ""
    async for chunk in llm.astream(messages):
        full_report += chunk.content or ""

    return {"final_report": full_report, "current_step": "END"}

# 5. [æ–°å¢] äººå·¥å®¡æ‰¹èŠ‚ç‚¹ (HumanReview)
def human_review_node(state: AgentState) -> dict:
    print("--- [äººå·¥å®¡æ‰¹] ç­‰å¾…ç”¨æˆ·ç¡®è®¤... ---")
    # è¿™é‡Œä»€ä¹ˆéƒ½ä¸ç”¨åšï¼Œåªæ˜¯ä¸ºäº†è®©å›¾åœåœ¨è¿™é‡Œ
    return {}

# --- 5. è·¯ç”±é€»è¾‘ (é€šç”¨åŒ–) ---

def universal_router(state: AgentState) -> str:
    """é€šç”¨è·¯ç”±å™¨: æ ¹æ® current_step ç›´æ¥æ˜ å°„åˆ°èŠ‚ç‚¹"""
    step = state.get("current_step")
    
    if step == "Research": return "Researcher"
    if step == "Analyze": return "Analyst"
    if step == "Write": return "Writer"
    if step == "END": return END
    return END # é»˜è®¤

def planner_router(state: AgentState) -> str:
    """è§„åˆ’å¸ˆè·¯ç”±: å†³å®šæ˜¯å»å®¡æ‰¹ï¼Œè¿˜æ˜¯ç›´æ¥å¼€å§‹å¹²æ´»"""
    needs_review = state.get("needs_review", False)
    
    if needs_review:
        return "HumanReview" # å»å®¡æ‰¹èŠ‚ç‚¹ï¼ˆä¼šè¢«ä¸­æ–­ï¼‰
    else:
        # ä¸éœ€è¦å®¡æ‰¹ï¼Œç›´æ¥å»ç¬¬ä¸€æ­¥ (å¤ç”¨é€šç”¨è·¯ç”±é€»è¾‘)
        return universal_router(state)

def qc_router(state: AgentState) -> str:
    """M10: è´¨é‡æ§åˆ¶è·¯ç”± (Analyst ä¸“ç”¨)"""
    results = state.get("analysis_results", [])
    last_result = results[-1] if results else ""
    
    is_error = False
    try:
        data = json.loads(last_result)
        if data.get("exit_code", 0) != 0 or data.get("error"): is_error = True
    except:
        if "æ‰§è¡Œé”™è¯¯" in str(last_result): is_error = True

    if is_error:
        retry_count = state.get("retry_count", 0)
        if retry_count < 3:
            print(f"ğŸ”¥ğŸ”¥ğŸ”¥ [QC] é”™è¯¯, é‡è¯•ç¬¬ {retry_count + 1} æ¬¡...")
            return "Analyst" # è¿˜åœ¨ Analyst èŠ‚ç‚¹é—­ç¯
        else:
            print("--- [QC] é‡è¯•è€—å°½ ---")
    
    # å¦‚æœæˆåŠŸï¼Œæˆ–è€…é‡è¯•è€—å°½ï¼Œåˆ™å» state é‡Œçš„ current_step æŒ‡å‘çš„åœ°æ–¹
    # (æ³¨æ„ï¼šanalyst_node å·²ç»æŠŠ current_step æ›´æ–°ä¸ºä¸‹ä¸€æ­¥äº†ï¼Œæ¯”å¦‚ END æˆ– Write)
    return universal_router(state)

# --- 6. æ„å»ºå›¾ ---
workflow = StateGraph(AgentState)

workflow.add_node("Planner", planner_node)
workflow.add_node("HumanReview", human_review_node)
workflow.add_node("Researcher", researcher_node)
workflow.add_node("Analyst", analyst_node)
workflow.add_node("Writer", writer_node)

workflow.set_entry_point("Planner")

# Planner -> Router
workflow.add_conditional_edges(
    "Planner",
    planner_router, # ä½¿ç”¨æ–°è·¯ç”±
    {
        "HumanReview": "HumanReview", 
        "Researcher": "Researcher",
        "Analyst": "Analyst", 
        "Writer": "Writer", 
        "END": END
    }
)

# [æ–°å¢] HumanReview -> Universal Router
# å¦‚æœç”¨æˆ·æ‰¹å‡†äº†ï¼ˆç»§ç»­è¿è¡Œï¼‰ï¼Œå°±ä»è¿™é‡Œè¿›å…¥ç¬¬ä¸€æ­¥
workflow.add_conditional_edges("HumanReview", universal_router)

# Researcher -> Router
workflow.add_conditional_edges("Researcher", universal_router)

# Analyst -> QC Router -> (Analyst or Next Node)
workflow.add_conditional_edges("Analyst", qc_router)

# Writer -> End
workflow.add_conditional_edges("Writer", lambda x: END)

memory = MemorySaver()
app = workflow.compile(checkpointer=memory, interrupt_before=["HumanReview"])