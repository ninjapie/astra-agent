import os
import operator
import base64
from typing import TypedDict, Annotated, List, Union
from langchain_openai import ChatOpenAI
from langchain_tavily import TavilySearch
from langchain_core.messages import BaseMessage, HumanMessage
from langgraph.graph import StateGraph, END
from langgraph.checkpoint.memory import MemorySaver
from dotenv import load_dotenv
from llama_index.core import VectorStoreIndex, Document, StorageContext
from llama_index.vector_stores.postgres import PGVectorStore
from llama_index.embeddings.openai import OpenAIEmbedding
import sqlalchemy
import json
from tools import python_interpreter, scrape_website

# --- 1. é…ç½®ä¸åˆå§‹åŒ– ---
load_dotenv()
llm = ChatOpenAI(model="gpt-4o", temperature=0)
web_search_tool = TavilySearch(max_results=3)

DB_NAME = "astra_db"
DB_USER = "maple" 
DB_PASSWORD = ""
DB_HOST = "localhost"
DB_PORT = "5432"

db_url = f"postgresql+psycopg2://{DB_USER}:{DB_PASSWORD}@{DB_HOST}:{DB_PORT}/{DB_NAME}"
engine = sqlalchemy.create_engine(db_url)

vector_store = PGVectorStore.from_params(
    database=DB_NAME, host=DB_HOST, port=DB_PORT, user=DB_USER, password=DB_PASSWORD,
    table_name="astra_collection", embed_dim=1536
)
embed_model = OpenAIEmbedding()
storage_context = StorageContext.from_defaults(vector_store=vector_store)
index = VectorStoreIndex.from_documents([], storage_context=storage_context, embed_model=embed_model)

# --- [ä¿®å¤ 1] å®šä¹‰ Reducer å‡½æ•°ï¼Œå…è®¸æœ€æ–°å€¼è¦†ç›–æ—§å€¼ ---
def replace_str(current: str, new: str) -> str:
    return new

# --- 2. çŠ¶æ€å®šä¹‰ ---
class AgentState(TypedDict):
    task: str
    plan: List[str] 
    final_report: str
    current_step: str
    analysis_results: Annotated[List[str], operator.add]
    retry_count: int
    image_data: str
    needs_review: bool
    visual_critique: Annotated[str, replace_str] 
    latest_image_path: str 

    # [ä¼˜é›…é‡æ„] åˆ é™¤ last_tool_usedï¼Œå¢åŠ é€šç”¨è¡Œä¸ºæ ‡è®°
    did_call_tool: bool  # è¿™è½®æ˜¯å¦åŠ¨æ‰‹äº†ï¼Ÿ
    has_generated_image: bool # è¿™è½®æ˜¯å¦å‡ºå›¾äº†ï¼Ÿ
    has_generated_html: bool # [M16 æ–°å¢] æ ‡è®°æ˜¯å¦ç”Ÿæˆäº† HTML

# --- 3. è¾…åŠ©å‡½æ•° ---
def get_next_step_name(plan: List[str], current_step_name: str) -> str:
    try:
        current_index = plan.index(current_step_name)
        if current_index + 1 < len(plan):
            return plan[current_index + 1]
        else:
            return "END"
    except ValueError:
        return "END"

def encode_image(image_path):
    with open(image_path, "rb") as image_file:
        return base64.b64encode(image_file.read()).decode('utf-8')

# --- 4. èŠ‚ç‚¹å®šä¹‰ ---

# 1. è§„åˆ’å¸ˆ (Planner)
async def planner_node(state: AgentState) -> dict:
    print("--- [è§„åˆ’å¸ˆ] å¼€å§‹å·¥ä½œ ---")
    task = state.get("task")
    
    prompt = f"""
    ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„é¡¹ç›®è§„åˆ’å¸ˆã€‚ä»»åŠ¡: {task}
    è¯·åˆ¶å®šæ­¥éª¤è®¡åˆ’ï¼Œä»ä»¥ä¸‹é€‰æ‹©:
    1. "Research": éœ€è¦å¤–éƒ¨ä¿¡æ¯ã€‚
    2. "Analyze": éœ€è¦è®¡ç®—ã€ä»£ç æ‰§è¡Œã€æµè§ˆç½‘é¡µæˆ–ç”Ÿæˆæ–‡ä»¶ã€‚
    3. "Write": éœ€è¦å†™ä¸€ä»½è¯¦ç»†çš„æ–‡å­—æ€»ç»“æŠ¥å‘Šæˆ–åˆ†æå†…å®¹ã€‚
    
    ã€å…³é”®è§„åˆ™ã€‘:
    - å¦‚æœä»»åŠ¡åªæ˜¯è¦æ±‚ç›´æ¥çš„ç­”æ¡ˆã€è®¡ç®—ç»“æœæˆ–ç”Ÿæˆç‰¹å®šæ–‡ä»¶(å¦‚"ç”Ÿæˆ5ä¸ªåå­—", "ç”»å¼ å›¾")ï¼Œ**ä¸è¦**åŒ…å« "Write"ã€‚

    åŒæ—¶ï¼Œè¯·åˆ¤æ–­è¯¥ä»»åŠ¡æ˜¯å¦éœ€è¦ã€ç”¨æˆ·å®¡æ‰¹ã€‘(needs_review):
    - å¦‚æœä»»åŠ¡æœ‰é£é™©ï¼ˆå¦‚åˆ é™¤æ–‡ä»¶ï¼‰ã€éå¸¸å¤æ‚ã€æˆ–è€…æŒ‡ä»¤æ¨¡ç³Šä¸ç¡®å®šï¼Œè¯·è®¾ä¸º trueã€‚
    - å¦‚æœä»»åŠ¡å¾ˆç®€å•ã€æ˜ç¡®ï¼Œè¯·è®¾ä¸º false (è‡ªåŠ¨æ‰§è¡Œ)ã€‚
    
    ã€é‡è¦ã€‘è¯·ä¸¥æ ¼è¿”å›ä»¥ä¸‹ JSON æ ¼å¼ï¼ˆçº¯ JSONï¼‰:
    {{
        "plan": ["Research", "Analyze"],
        "needs_review": false
    }}
    """
    messages = [HumanMessage(content=prompt)]
    
    full_plan_str = ""
    async for chunk in llm.astream(messages):
        full_plan_str += chunk.content or ""
    
    try:
        clean_str = full_plan_str.replace("```json", "").replace("```", "").strip()
        result_data = json.loads(clean_str)
        plan_steps = result_data.get("plan", ["Research", "Write"])
        needs_review = result_data.get("needs_review", False)
    except Exception as e:
        print(f"è®¡åˆ’è§£æå¤±è´¥ï¼Œé™çº§å¤„ç†: {e}")
        plan_steps = ["Research", "Write"]
        needs_review = True 
    
    first_step = plan_steps[0] if plan_steps else "END"
    return {"plan": plan_steps, "current_step": first_step, "needs_review": needs_review}

# 2. ç ”ç©¶å‘˜ (Researcher)
def researcher_node(state: AgentState) -> dict:
    print("--- [ç ”ç©¶å‘˜] å¼€å§‹æœç´¢ ---")
    task = state.get("task")
    print(f'task: {task}')
    try:
        research_results = web_search_tool.invoke(task)
    except Exception as e:
        research_results = [f"æœç´¢å¤±è´¥: {e}"]
    
    print(f"search results: {research_results}")
    MAX_CHARS = 4000
    documents = []
    for result in research_results['results']:
        content = str(result)
        if len(content) > MAX_CHARS: content = content[:MAX_CHARS] + "..."
        documents.append(Document(text=content, metadata={"task": task}))
    
    if documents:
        index.insert_nodes(documents)
    
    plan = state.get("plan", [])
    next_step = get_next_step_name(plan, "Research")
    print(f"next step: {next_step}")
    return {"current_step": next_step}

# 3. åˆ†æå¸ˆ (Analyst)
async def analyst_node(state: AgentState) -> dict:
    print("--- [åˆ†æå¸ˆ] å¼€å§‹åˆ†æ ---")
    task = state.get("task")
    image_data = state.get("image_data") 
    previous_results = state.get("analysis_results", [])
    retry_count = state.get("retry_count", 0)
    visual_critique = state.get("visual_critique", "PASS") 
    
    query_engine = index.as_query_engine(similarity_top_k=3)
    rag_context = await query_engine.aquery(task)

    # [M15 æ ¸å¿ƒ] æ„å»ºå®Œæ•´çš„å†å²è®°å¿†ä¸Šä¸‹æ–‡ (Memory Stream)
    history_context = ""
    if previous_results:
        history_context = "\n\n=== ğŸ“œ å†å²æ“ä½œè®°å½• (Memory Stream) ===\n"
        for i, res in enumerate(previous_results):
            # æˆªæ–­è¿‡é•¿çš„è¾“å‡º (å¦‚ç½‘é¡µå…¨æ–‡)ï¼Œä½†ä¿ç•™è¶³å¤Ÿé•¿åº¦ä¾›åˆ†æ
            preview = res[:3000] + "...(å†…å®¹è¿‡é•¿å·²æˆªæ–­)" if len(res) > 3000 else res
            history_context += f"--- Step {i+1} Output ---\n{preview}\n\n"
        history_context += "========================================\n"
    
    prompt = f"""
      ä½ æ˜¯ä¸€ä¸ªå…¨èƒ½æ•°æ®åˆ†æå¸ˆã€‚ä»»åŠ¡: {task}
      èƒŒæ™¯: {rag_context}

      {history_context}

      ã€å½“å‰çŠ¶æ€ä¸å†³ç­–ã€‘:
      è¯·å›é¡¾ä¸Šé¢çš„ [å†å²æ“ä½œè®°å½•] æ¥å†³å®šä¸‹ä¸€æ­¥ï¼š
      1. **ä¿¡æ¯ä¸è¶³ï¼Ÿ** -> è°ƒç”¨ `scrape_website(url)` è·å–è¯¦æƒ…ã€‚
      2. **ç¼ºåº“ï¼Ÿ** -> è°ƒç”¨ `install('package')`ã€‚
      3. **æœ‰æ•°æ®äº†ï¼Ÿ** -> ç¼–å†™ Python ä»£ç å¤„ç†æ•°æ®æˆ–ç”»å›¾ã€‚
      4. **æŠ¥é”™äº†ï¼Ÿ** -> æ ¹æ®é”™è¯¯ä¿¡æ¯ä¿®æ­£ä»£ç ã€‚

      ã€äº¤äº’å¼å›¾è¡¨ (Interactive)ã€‘:
      1. å¦‚æœç”¨æˆ·è¦æ±‚â€œäº¤äº’å¼â€ã€â€œåŠ¨æ€â€æˆ–â€œå¯ç¼©æ”¾â€çš„å›¾è¡¨ï¼Œ**å¿…é¡»**ç”Ÿæˆ HTML æ–‡ä»¶ã€‚
      2. **æ¨èåº“**: `pyecharts` (é¦–é€‰) æˆ– `plotly`ã€‚
      3. **å®‰è£…**: åˆ«å¿˜äº†å…ˆ `install('pyecharts')`ã€‚
      4. **ä¿å­˜**: å¿…é¡»æ¸²æŸ“å¹¶ä¿å­˜ä¸º `/app/output.html` (ä¾‹å¦‚ `bar.render("/app/output.html")`)ã€‚

      ã€æ·±åº¦æµè§ˆã€‘:
      1. å¦‚æœèƒŒæ™¯ä¿¡æ¯(rag_context)å¤ªç®€ç•¥ï¼Œæˆ–è€…åŒ…å« URL é“¾æ¥ï¼Œä½ å¯ä»¥ä½¿ç”¨ `scrape_website(url)` å·¥å…·æ¥è¯»å–ç½‘é¡µå…¨æ–‡ã€‚
      2. è¿™æ˜¯ä¸€ä¸ªè·å–è¯¦ç»†æŠ€æœ¯æ–‡æ¡£ã€é•¿ç¯‡æŠ¥é“æˆ–å…·ä½“å‚æ•°çš„ç»ä½³æ–¹å¼ã€‚
      3. **æµç¨‹å»ºè®®**: è§‰å¾—ä¿¡æ¯ä¸å¤Ÿ -> `scrape_website` -> è·å¾—ä¿¡æ¯ -> `python_interpreter` å¤„ç†ã€‚

      ã€åŠ¨æ€ä¾èµ–ç®¡ç†ã€‘(IMPORTANT):
      1. ç¯å¢ƒå·²å†…ç½® `install(package_name)` å‡½æ•°ã€‚
      2. å¦‚æœä»»åŠ¡éœ€è¦å¤–éƒ¨åº“ï¼ˆå¦‚ `wordcloud`, `qrcode`, `yfinance`, `openpyxl` ç­‰ï¼‰ï¼Œ**å¿…é¡»**åœ¨ import ä¹‹å‰è°ƒç”¨å®ƒã€‚
      3. **ç¤ºä¾‹**:
         ```python
         install("wordcloud") # å…ˆå®‰è£…
         from wordcloud import WordCloud # åå¯¼å…¥
         # ... ä½ çš„ä»£ç 
         ```
    
      ã€åæ­»å¾ªç¯åè®®ã€‘(CRITICAL):
      1. **ä¸¥ç¦é‡å¤æ“ä½œ**: åœ¨è°ƒç”¨å·¥å…·å‰ï¼Œå¿…é¡»æ£€æŸ¥ [å†å²æ“ä½œè®°å½•]ã€‚å¦‚æœä½ ï¼ˆæˆ–ä¹‹å‰çš„æ­¥éª¤ï¼‰å·²ç»æŠ“å–è¿‡æŸä¸ª URLï¼Œ**ç»ä¸å…è®¸**å†æ¬¡æŠ“å–åŒä¸€ä¸ª URLã€‚
      2. **å¤„ç†å¤±è´¥**: å¦‚æœä¸Šä¸€æ­¥æŠ“å–çš„å†…å®¹ä¸ç†æƒ³ï¼ˆå¦‚ä¸ºç©ºæˆ–ä¹±ç ï¼‰ï¼Œè¯·å°è¯•æ›´æ¢ URLï¼Œæˆ–è€…ç›´æ¥åŸºäºç°æœ‰ä¿¡æ¯ç¼–å†™ä»£ç ï¼Œ**ä¸è¦**åŸåœ°é‡è¯•ã€‚
      3. **æ¨è¿›æµç¨‹**: å¦‚æœä½ å·²ç»æœ‰äº†æŠ“å–ç»“æœï¼ˆå³ä½¿åªæ˜¯éƒ¨åˆ†ï¼‰ï¼Œè¯·ç«‹å³è½¬å…¥ä¸‹ä¸€ä¸ªæ­¥éª¤ã€‚

      ã€ä»£ç æ‰§è¡Œä¸é˜²å¹»è§‰åè®®ã€‘(CRITICAL):
      1. **Fact Check**: å¦‚æœä½ æ²¡æœ‰ç¼–å†™ä»£ç è°ƒç”¨ `python_interpreter`ï¼Œ**ç»å¯¹ç¦æ­¢**åœ¨å›å¤ä¸­å£°ç§°â€œæ–‡ä»¶å·²ä¿å­˜â€æˆ–æåŠ `/app/output.png`ã€‚
      2. åªæœ‰å½“ä½ ç”Ÿæˆçš„ Python ä»£ç ä¸­ç¡®å®åŒ…å« `plt.savefig('/app/output.png')` æ—¶ï¼Œæ‰å…è®¸åœ¨ä»£ç æ³¨é‡Šæˆ–æœ€ç»ˆæ€»ç»“ä¸­æåŠè¯¥æ–‡ä»¶ã€‚
      3. å¦‚æœä»»åŠ¡ä¸éœ€è¦ä»£ç ï¼Œè¯·ç›´æ¥ç»™å‡ºæ–‡å­—ç»“è®ºï¼Œä¸è¦å‡è£…è¿è¡Œäº†ä»£ç ã€‚
      
      ã€ä»£ç æ‰§è¡Œè¦æ±‚ã€‘:
      1. åŠ¡å¿…ä½¿ç”¨ print() è¾“å‡ºæœ€ç»ˆç»“æœã€‚
      2. ä»…åœ¨éœ€è¦æ—¶ç»˜å›¾ (/app/output.png)ã€‚
      3. **ä¸è¦**åœ¨ä»£ç ä¸­è®¾ç½®ç»˜å›¾é£æ ¼ï¼Œç¯å¢ƒå·²é¢„ç½®ã€‚
      4. ä¼˜å…ˆä½¿ç”¨ **Seaborn** (`sns`) ç»˜å›¾ã€‚
      
      ã€é€šç”¨ç¾å­¦ä¸é…è‰²è§„èŒƒã€‘(å¿…é¡»ä¸¥æ ¼éµå®ˆ):
      1. **ä¸¥ç¦ç¡¬ç¼–ç é¢œè‰²**: ç¦æ­¢å‡ºç° `color=['red', 'blue']`ã€‚
      2. **åˆ†ç±»å›¾è¡¨**: å¿…é¡»é€šè¿‡ `hue` å‚æ•°æ¿€æ´»è‡ªåŠ¨é…è‰²ï¼Œä¾‹å¦‚ `sns.barplot(x=vars, y=vals, hue=vars, legend=False)`ã€‚
      3. **é¥¼å›¾**: å¿…é¡»æ‰‹åŠ¨è°ƒç”¨è‰²ç›˜ `plt.pie(..., colors=sns.color_palette())`ã€‚
      4. **çƒ­åŠ›å›¾**: æ¨è `cmap='YlGnBu'`ã€‚
    """
    
    # è§†è§‰ä¿®æ­£ Prompt
    if visual_critique and visual_critique != "PASS":
        prompt += f"\n\nğŸ”¥ğŸ”¥ğŸ”¥ã€è§†è§‰ä¿®æ­£æ¨¡å¼ã€‘ğŸ”¥ğŸ”¥ğŸ”¥\nä¸Šä¸€ç‰ˆä»£ç ç”Ÿæˆçš„å›¾ç‰‡è¢«è§†è§‰æ¨¡å‹é©³å›ã€‚æ„è§å¦‚ä¸‹:\n{visual_critique}\nè¯·ä¿®æ”¹ä»£ç ä»¥ä¿®å¤ä¸Šè¿°å®¡ç¾æˆ–æ˜¾ç¤ºé—®é¢˜ã€‚"
    elif retry_count > 0 and previous_results:
         prompt += f"\nã€ä¿®å¤é”™è¯¯ã€‘ä¸Šæ¬¡å¤±è´¥: {previous_results[-1]}\nè¯·ä¿®æ­£ä»£ç ã€‚"
    
    if image_data:
        print("--- [åˆ†æå¸ˆ] æ”¶åˆ°å›¾ç‰‡, æ­£åœ¨è¿›è¡Œè§†è§‰åˆ†æ... ---")
        message_content = [
            {"type": "text", "text": prompt},
            {"type": "image_url", "image_url": {"url": f"data:image/jpeg;base64,{image_data}"}}
        ]
    else:
        message_content = prompt
    
    analyst_llm = llm.bind_tools([python_interpreter, scrape_website])
    messages = [HumanMessage(content=message_content)]
    
    response = await analyst_llm.ainvoke(messages)
    analysis_output = response.content

    did_call_tool = False
    has_generated_image = False
    has_generated_html = False
    latest_image_path = None

    if response.tool_calls:
        did_call_tool = True
        for tool_call in response.tool_calls:
            tool_name = tool_call["name"]
            tool_args = tool_call["args"]

            if tool_name == "python_interpreter":
                code = tool_args["code"]
                print(f"--- [åˆ†æå¸ˆ] æ‰§è¡Œä»£ç ... ---")
                tool_result = python_interpreter.invoke(code)
                analysis_output = tool_result

                try:
                    output_data = json.loads(tool_result)
                    files = output_data.get("files", [])
                    for f in files:
                        if f.get("type") == "html":
                            has_generated_html = True
                            print(f"--- [åˆ†æå¸ˆ] ç”Ÿæˆäº†äº¤äº’å¼ HTML ---")
                        elif f.get("type") == "image" and f.get("saved_path"):
                            latest_image_path = f["saved_path"]
                            has_generated_image = True
                            print(f"--- [åˆ†æå¸ˆ] æ•è·åˆ°ç”Ÿæˆå›¾ç‰‡: {latest_image_path} ---")
                except:
                    pass
            elif tool_name == "scrape_website":
                print(f"--- [åˆ†æå¸ˆ] è°ƒç”¨æµè§ˆå™¨æŠ“å–: {tool_args.get('url')} ---")
                tool_result = scrape_website.invoke(tool_args.get("url"))
                # å°†æŠ“å–ç»“æœä½œä¸ºè¡¥å……ä¿¡æ¯ï¼Œå¯èƒ½éœ€è¦å†æ¬¡æ€è€ƒ?
                # ç®€åŒ–èµ·è§ï¼Œæˆ‘ä»¬å°†ç»“æœå­˜å…¥ analysis_outputï¼Œä¾›ä¸‹ä¸€è½®æˆ– Writer ä½¿ç”¨
                analysis_output = f"ã€ç½‘é¡µæŠ“å–ç»“æœã€‘:\n{tool_result[:2000]}..." # é¢„è§ˆ
    # é˜²å¹»è§‰æ£€æŸ¥
    if not did_call_tool and "/app/output.png" in str(analysis_output):
        print("--- [ç³»ç»Ÿçº é”™] æ£€æµ‹åˆ° Analyst å¹»è§‰ï¼Œæ­£åœ¨ä¿®æ­£... ---")
        warning_msg = "[ç³»ç»Ÿæç¤º]: åˆ†æå¸ˆæœªæ‰§è¡Œä»»ä½•ä»£ç ï¼Œå› æ­¤æ²¡æœ‰ç”Ÿæˆå›¾è¡¨ã€‚è¯·å¿½ç•¥å…³äº /app/output.png çš„æè¿°ï¼Œä»…å‚è€ƒæ–‡å­—åˆ†æã€‚"
        analysis_output += warning_msg

    current_retry = state.get("retry_count", 0)
    
    return {
        "analysis_results": [analysis_output], 
        "retry_count": current_retry + 1,
        "latest_image_path": latest_image_path,
        "did_call_tool": did_call_tool,          # [æ–°]
        "has_generated_image": has_generated_image, # [æ–°]
        "has_generated_html": has_generated_html
    }

# 4. è§†è§‰è¯„è®ºå®¶ (Visual Critic)
async def visual_critic_node(state: AgentState) -> dict:
    # [M16] å¦‚æœæ˜¯ HTMLï¼Œç›®å‰ Visual Critic æ— æ³•æ£€æŸ¥ (å› ä¸ºæ˜¯ä»£ç )ï¼Œç›´æ¥é€šè¿‡
    # æœªæ¥å¯ä»¥åŠ å…¥ä»£ç æ£€æŸ¥ï¼Œä½†ç°åœ¨å…ˆæ”¾è¡Œ
    if state.get("has_generated_html"):
        print("--- [è§†è§‰è¯„è®ºå®¶] æ£€æµ‹åˆ° HTML äº¤äº’å›¾è¡¨ï¼Œè‡ªåŠ¨é€šè¿‡ (HTML Bypass) ---")
        return {"visual_critique": "PASS"}

    image_path = state.get("latest_image_path")
    
    # æ— å›¾åˆ™ç›´æ¥é€šè¿‡
    if not image_path or not os.path.exists(image_path):
        print("--- [è§†è§‰è¯„è®ºå®¶] æ— å›¾ç‰‡ï¼Œè·³è¿‡æ£€æŸ¥ ---")
        return {"visual_critique": "PASS"}
    
    print(f"--- [è§†è§‰è¯„è®ºå®¶] æ­£åœ¨å®¡æŸ¥å›¾ç‰‡: {image_path} ---")
    base64_image = encode_image(image_path)

    # [ä¿®å¤] è·å–æ›´ä¸°å¯Œçš„ä¸Šä¸‹æ–‡
    task_description = state.get("task", "æœªæä¾›ä»»åŠ¡æè¿°")
    analysis_results = state.get("analysis_results", [])

    # å°è¯•è·å–æœ€è¿‘çš„å·¥å…·è¾“å‡ºä½œä¸ºå‚è€ƒï¼Œä½†ä¸»è¦ä¾é  task
    tool_output_snippet = analysis_results[-1][:500] if analysis_results else "æ— å·¥å…·è¾“å‡º"
    
    critic_prompt = f"""
    ä½ æ˜¯ä¸€ä¸ªé€šç”¨çš„è§†è§‰è´¨é‡æ§åˆ¶ä¸“å®¶ (Visual QA)ã€‚

    ã€åŸå§‹ä»»åŠ¡ç›®æ ‡ã€‘:
    "{task_description}"
    
    ã€æœ€è¿‘çš„æ‰§è¡Œæ—¥å¿—(ä»…ä¾›å‚è€ƒ)ã€‘:
    {tool_output_snippet}...
    
    ã€ä»»åŠ¡ã€‘:
    è¯·æ£€æŸ¥ä¸Šä¼ çš„å›¾ç‰‡æ˜¯å¦ç¬¦åˆã€åŸå§‹ä»»åŠ¡ç›®æ ‡ã€‘ï¼Œå¹¶æ£€æŸ¥æ˜¯å¦å­˜åœ¨**æ˜æ˜¾çš„è§†è§‰ç¼ºé™·**ã€‚
    
    ã€åˆ¤æ–­æ ‡å‡†ã€‘:
    1. **ç›¸å…³æ€§**: å›¾ç‰‡å†…å®¹æ˜¯å¦çœ‹ä¼¼åœ¨å“åº”ç”¨æˆ·çš„ä»»åŠ¡ï¼Ÿ(ä¾‹å¦‚ç”¨æˆ·è¦äºŒç»´ç ï¼Œå›¾å°±æ˜¯äºŒç»´ç )ã€‚
       - æ³¨æ„ï¼šå¦‚æœæ‰§è¡Œæ—¥å¿—æ˜¯ JSON æ ¼å¼æˆ–ä»£ç æ—¥å¿—ï¼Œè¯·å¿½ç•¥æ—¥å¿—å†…å®¹ï¼Œ**é‡ç‚¹å¯¹æ¯”å›¾ç‰‡å’Œ[åŸå§‹ä»»åŠ¡ç›®æ ‡]**ã€‚
    2. **å¯è¯»æ€§**: æ˜¯å¦å­˜åœ¨ä¹±ç ã€ä¸¥é‡æ¨¡ç³Šã€å†…å®¹è¢«æˆªæ–­ï¼Ÿ
    3. **å®Œæ•´æ€§**: å›¾ç‰‡æ˜¯å¦å®Œæ•´ï¼Ÿ
    
    å¦‚æœä¸ç¬¦åˆæè¿°æˆ–æœ‰ä¸¥é‡ç¼ºé™·ï¼Œè¯·ç»™å‡ºå…·ä½“çš„ä¿®æ”¹å»ºè®®ã€‚
    å¦‚æœå›¾ç‰‡ç¬¦åˆæè¿°ä¸”è´¨é‡åˆæ ¼ï¼Œæˆ–è€…ä½ ä¸ç¡®å®šä½†å›¾ç‰‡çœ‹èµ·æ¥æ²¡æœ‰æŠ€æœ¯é”™è¯¯ï¼Œè¯·**ä»…å›å¤ "PASS"**ã€‚
    """
    
    message = HumanMessage(
        content=[
            {"type": "text", "text": critic_prompt},
            {"type": "image_url", "image_url": {"url": f"data:image/jpeg;base64,{base64_image}"}}
        ]
    )
    
    response = await llm.ainvoke([message])
    critique = response.content
    print(f"--- [è§†è§‰è¯„è®ºå®¶] æ„è§: {critique} ---")
    
    return {"visual_critique": critique}

# 5. å†™æ‰‹ (Writer)
async def writer_node(state: AgentState) -> dict:
    print("--- [å†™æ‰‹] å¼€å§‹å†™ä½œ ---")
    task = state.get("task")
    query_engine = index.as_query_engine(similarity_top_k=3)
    rag_context = await query_engine.aquery(task)
    analysis_results = state.get("analysis_results", [])
    
    prompt = f"""
    ä¸“ä¸šå†™æ‰‹ã€‚ä»»åŠ¡: {task}
    ä¸Šä¸‹æ–‡: {rag_context}
    æ•°æ®åˆ†æ: {analysis_results}
    è¯·æ’°å†™æŠ¥å‘Šã€‚å¦‚æœç”Ÿæˆäº† HTML å›¾è¡¨ï¼Œè¯·åœ¨æŠ¥å‘Šä¸­æç¤ºç”¨æˆ·ä¸‹è½½æˆ–æŸ¥çœ‹é™„ä»¶ã€‚
    """
    messages = [HumanMessage(content=prompt)]
    
    full_report = ""
    async for chunk in llm.astream(messages):
        full_report += chunk.content or ""

    return {"final_report": full_report, "current_step": "END"}

# 6. äººå·¥å®¡æ‰¹èŠ‚ç‚¹
def human_review_node(state: AgentState) -> dict:
    print("--- [äººå·¥å®¡æ‰¹] ç­‰å¾…ç”¨æˆ·ç¡®è®¤... ---")
    return {}

# --- 5. è·¯ç”±é€»è¾‘ ---

def universal_router(state: AgentState) -> str:
    step = state.get("current_step")
    if step == "Research": return "Researcher"
    if step == "Analyze": return "Analyst"
    if step == "Write": return "Writer"
    if step == "END": return "END"
    return "END"

def planner_router(state: AgentState) -> str:
    if state.get("needs_review"): return "HumanReview"
    return universal_router(state)

def analyst_router(state: AgentState) -> str:
    """
    é€šç”¨è¡Œä¸ºè·¯ç”±ï¼š
    1. æ²¡è°ƒå·¥å…·? -> è¯´æ˜æƒ³æ˜ç™½äº†/æ²¡äº‹å¹²äº† -> å» Writer
    2. è°ƒäº†å·¥å…·ä¸”å‡ºå›¾äº†? -> è¯´æ˜æœ‰ä½œå“ -> å» VisualCritic æ£€æŸ¥
    3. è°ƒäº†å·¥å…·ä½†æ²¡å‡ºå›¾? -> è¯´æ˜åªæ˜¯ç”±è·å–äº†ä¸­é—´ä¿¡æ¯(æŠ“å–/è®¡ç®—) -> å› Analyst ç»§ç»­æ¶ˆåŒ–
    """
    did_call_tool = state.get("did_call_tool", False)
    has_image = state.get("has_generated_image", False)
    has_html = state.get("has_generated_html", False)
    retry_count = state.get("retry_count", 0)
    
    # 1. [æ€è€ƒç»“æŸ]ï¼šæ²¡åŠ¨æ‰‹ï¼Œåªæ˜¯åœ¨è¯´è¯ -> ä»»åŠ¡å®Œæˆ
    if not did_call_tool:
        print("--- [è·¯ç”±] åˆ†æå¸ˆæœªè°ƒç”¨å·¥å…·ï¼Œè®¤ä¸ºåˆ†æç»“æŸ ---")
        
        # è¿˜è¦æ£€æŸ¥ä¸€ä¸‹æœ‰æ²¡æœ‰æŠ¥é”™ (å…¼å®¹æ—§çš„ QC é€»è¾‘)
        # ... (å¯ä»¥ä¿ç•™ç®€å•çš„æ–‡æœ¬é”™è¯¯æ£€æŸ¥ï¼Œä¹Ÿå¯ä»¥çœç•¥)
        
        plan = state.get("plan", [])
        next_step = get_next_step_name(plan, "Analyze")
        if next_step == "Write": return "Writer"
        return "END"

    # 2. [ä½œå“äº§å‡º]ï¼šåŠ¨æ‰‹äº†ï¼Œä¸”ç”Ÿæˆäº†å›¾ç‰‡ -> å»è´¨æ£€
    if has_image or has_html:
        print("--- [è·¯ç”±] æ£€æµ‹åˆ°è§†è§‰äº§å‡º (Img/HTML) -> VisualCritic ---")
        return "VisualCritic"

    # 3. [ä¸­é—´çŠ¶æ€]ï¼šåŠ¨æ‰‹äº†(æ¯”å¦‚æŠ“å–/å®‰è£…)ï¼Œä½†æ²¡å‡ºå›¾ -> å¿…å®šæ˜¯ä¸­é—´æ­¥éª¤
    # å¼ºåˆ¶é—­ç¯ï¼Œè®© Analyst æ¶ˆåŒ–åˆšæ‰è·å¾—çš„ä¿¡æ¯
    if did_call_tool:
        if retry_count < 15: 
            print("--- [è·¯ç”±] å·¥å…·æ‰§è¡Œå®Œæ¯•(æ— å›¾) -> Analyst ç»§ç»­æ€è€ƒ ---")
            return "Analyst"
        else:
            return "Writer"
    
    print("--- [è·¯ç”±] åˆ†æå¸ˆåœæ­¢æ“ä½œ -> Writer ---")
    plan = state.get("plan", [])
    next_step = get_next_step_name(plan, "Analyze")
    if next_step == "Write": return "Writer"
    return "END"

# [ä¿®å¤ 5] è§†è§‰è·¯ç”±ï¼šé€šè¿‡åå» Writer
def critic_router(state: AgentState) -> str:
    critique = state.get("visual_critique", "PASS")
    retry_count = state.get("retry_count", 0)
    
    # 1. é€šè¿‡ï¼Œå» Writer (æˆ–è€…æ ¹æ® plan å†³å®š)
    if critique == "PASS":
        plan = state.get("plan", [])
        next_step = get_next_step_name(plan, "Analyze")
        if next_step == "Write": 
            return "Writer"
        else:
            print("--- [æµç¨‹] è®¡åˆ’å·²å®Œæˆï¼Œä»»åŠ¡ç»“æŸ ---")
            return "END"
        
    # 2. ä¸é€šè¿‡ï¼Œå›ç‚‰é‡é€ 
    if retry_count < 3:
        print("ğŸ”™ [è§†è§‰è·¯ç”±] é©³å›! è¿”å› Analyst é‡ç”»...")
        return "Analyst"
    
    # 3. å®åœ¨æ”¹ä¸åŠ¨äº†ï¼Œå» Writer
    return "Writer"

# --- 6. æ„å»ºå›¾ ---
workflow = StateGraph(AgentState)

workflow.add_node("Planner", planner_node)
workflow.add_node("HumanReview", human_review_node)
workflow.add_node("Researcher", researcher_node)
workflow.add_node("Analyst", analyst_node)
workflow.add_node("VisualCritic", visual_critic_node)
workflow.add_node("Writer", writer_node)

workflow.set_entry_point("Planner")

# Planner è·¯ç”±
workflow.add_conditional_edges(
    "Planner",
    planner_router,
    {"HumanReview": "HumanReview", "Researcher": "Researcher", "Analyst": "Analyst", "Writer": "Writer", "END": END}
)

workflow.add_conditional_edges(
    "HumanReview",
    universal_router,
    {"Researcher": "Researcher", "Analyst": "Analyst", "Writer": "Writer", "END": END}
)
workflow.add_conditional_edges(
    "Researcher",
    universal_router,
    {"Researcher": "Researcher", "Analyst": "Analyst", "Writer": "Writer", "END": END}
)

# [ä¿®å¤ 6] Analyst åªæœ‰ä¸€æ¡æ¡ä»¶å‡ºè¾¹
workflow.add_conditional_edges(
    "Analyst",
    analyst_router,
    {"Analyst": "Analyst", "VisualCritic": "VisualCritic", "Writer": "Writer", "END": END}
)

# VisualCritic è·¯ç”±
workflow.add_conditional_edges(
    "VisualCritic",
    critic_router,
    {"Analyst": "Analyst", "Writer": "Writer", "END": END}
)

workflow.add_conditional_edges("Writer", lambda x: END)

memory = MemorySaver()
app = workflow.compile(checkpointer=memory, interrupt_before=["HumanReview"])