import os
from typing import TypedDict, Annotated, List
from langchain_openai import ChatOpenAI
from langchain_tavily import TavilySearch
from langchain.messages import SystemMessage
from langgraph.graph import StateGraph, END
from langgraph.checkpoint.memory import MemorySaver
from dotenv import load_dotenv

# --- æ­¥éª¤ 1: åŠ è½½ API å¯†é’¥ ---
load_dotenv()

# --- æ­¥éª¤ 2: å®šä¹‰ "Agent å›¢é˜Ÿ" ä½¿ç”¨çš„å·¥å…· ---
# ç ”ç©¶å‘˜ Agent å°†ä½¿ç”¨ Tavily (Tavily) æœç´¢å·¥å…·
web_search_tool = TavilySearch(max_results=3)

# --- æ­¥éª¤ 3: å®šä¹‰ "Agent çŠ¶æ€" (AgentState) ---
# è¿™å°±åƒæ˜¯å›¢é˜Ÿå…±äº«çš„ "å…¬æ–‡åŒ…" æˆ– "é¡¹ç›®æ¿"
class AgentState(TypedDict):
    task: str                 # ç”¨æˆ·çš„åˆå§‹ä»»åŠ¡
    research_data: List[str]  # ç ”ç©¶å‘˜æ‰¾åˆ°çš„æ•°æ®
    final_report: str         # å†™æ‰‹ç”Ÿæˆçš„æœ€ç»ˆæŠ¥å‘Š

# --- æ­¥éª¤ 4: å®šä¹‰ "Agent èŠ‚ç‚¹" (Node) ---
# æˆ‘ä»¬å°†ä½¿ç”¨ ChatOpenAI (GPT-4o/GPT-4) ä½œä¸º Agent çš„ "å¤§è„‘"
llm = ChatOpenAI(model="gpt-4o", temperature=0)

# 1. ç ”ç©¶å‘˜ (Researcher) èŠ‚ç‚¹
def researcher_node(state: AgentState) -> AgentState:
    print("--- æ­£åœ¨è°ƒç”¨ [ç ”ç©¶å‘˜] ---")
    task = state.get("task")
    
    # 1. åˆ›å»ºç ”ç©¶æç¤º
    prompt = f"""
    ä½ æ˜¯ä¸€ä¸ªä¸–ç•Œçº§çš„ AI ç ”ç©¶å‘˜ã€‚
    è¯·æ ¹æ®ä»¥ä¸‹ä»»åŠ¡ï¼Œä¸ºæˆ‘è¿›è¡Œæ·±å…¥çš„ç½‘ç»œæœç´¢ï¼š
    ä»»åŠ¡ï¼š{task}
    
    è¯·è¿”å› 3 ä¸ªæœ€ç›¸å…³çš„æœç´¢ç»“æœã€‚
    """
    
    # 2. è°ƒç”¨ LLM (å¤§è„‘) å’Œ Tool (å·¥å…·)
    messages = [SystemMessage(content=prompt)]
    research_results = web_search_tool.invoke(task)
    
    print(f"--- [ç ”ç©¶å‘˜] æ‰¾åˆ°äº† {len(research_results)} æ¡ç»“æœ ---")
    
    # 3. æ›´æ–° "å…¬æ–‡åŒ…" (AgentState)
    return {
        "research_data": research_results
    }

# 2. å†™æ‰‹ (Writer) èŠ‚ç‚¹
def writer_node(state: AgentState) -> AgentState:
    print("--- æ­£åœ¨è°ƒç”¨ [å†™æ‰‹] ---")
    research_data = state.get("research_data")
    
    # 1. åˆ›å»ºå†™ä½œæç¤º
    prompt = f"""
    ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ç§‘æŠ€æŠ¥å‘Šå†™æ‰‹ã€‚
    è¯·æ ¹æ®ä»¥ä¸‹ [ç ”ç©¶æ•°æ®]ï¼Œæ’°å†™ä¸€ä»½ç®€æ´ã€ä¸“ä¸šçš„æ€»ç»“æŠ¥å‘Šï¼š

    [ç ”ç©¶æ•°æ®]:
    {research_data}
    
    è¯·ç›´æ¥è¾“å‡ºè¿™ä»½æŠ¥å‘Šã€‚
    """
    
    # 2. è°ƒç”¨ LLM (å¤§è„‘)
    messages = [SystemMessage(content=prompt)]
    report = llm.invoke(messages).content
    
    print("--- [å†™æ‰‹] å·²å®ŒæˆæŠ¥å‘Š ---")
    
    # 3. æ›´æ–° "å…¬æ–‡åŒ…" (AgentState)
    return {
        "final_report": report
    }

# --- æ­¥éª¤ 5: æ„å»º "å¤šæ™ºèƒ½ä½“å›¾" (LangGraph) ---
workflow = StateGraph(AgentState)

# 1. æ·»åŠ èŠ‚ç‚¹ (æˆ‘ä»¬çš„"å›¢é˜Ÿæˆå‘˜")
workflow.add_node("Researcher", researcher_node)
workflow.add_node("Writer", writer_node)

# 2. å®šä¹‰æµç¨‹ (Edges)
workflow.set_entry_point("Researcher") # ä»»åŠ¡ä» "ç ”ç©¶å‘˜" å¼€å§‹
workflow.add_edge("Researcher", "Writer") # "ç ”ç©¶å‘˜" å®Œæˆå, äº¤ç»™ "å†™æ‰‹"
workflow.add_edge("Writer", END) # "å†™æ‰‹" å®Œæˆå, æµç¨‹ç»“æŸ (END)

# 3. ç¼–è¯‘å›¾ (Compile)
# checkpointer æ˜¯å¯é€‰çš„, ä½†å®ƒèƒ½è®©æˆ‘ä»¬"è®°ä½"æ¯ä¸€æ­¥çš„çŠ¶æ€
memory = MemorySaver()
app = workflow.compile(checkpointer=memory)

# --- æ­¥éª¤ 6: è¿è¡Œæˆ‘ä»¬çš„ "Astra" Agent ---
if __name__ == "__main__":
    print("ğŸš€ Astra Agent å·²å¯åŠ¨... (M1 ç‰ˆæœ¬)")
    
    # å®šä¹‰ä¸€ä¸ªä¼šè¯ ID (è¿™æ ·æˆ‘ä»¬å¯ä»¥"è®°ä½"è¿›åº¦)
    session_config = {"configurable": {"thread_id": "session-1"}}
    
    # æˆ‘ä»¬çš„å¤æ‚ä»»åŠ¡
    task = "è°ƒç ” 2025 å¹´ AI Agent å¸‚åœºçš„æœ€æ–°è¶‹åŠ¿, ç‰¹åˆ«æ˜¯å…³äº Manus, OpenAI å’Œ Google çš„"
    
    # å¯åŠ¨ Agent å›¢é˜Ÿ!
    # app.stream() ä¼šè¿”å›æ¯ä¸€æ­¥çš„"å®æ—¶"è¾“å‡º
    
    # æˆ‘ä»¬ç”¨ .invoke() ä¸€æ¬¡æ€§è¿è¡Œåˆ°åº•
    print(f"--- ä»»åŠ¡: {task} ---")
    
    # è§¦å‘å›¾çš„è¿è¡Œ
    final_state = app.invoke(
        {"task": task},
        config=session_config
    )
    
    print("\n--- æµç¨‹å·²ç»“æŸ ---")
    
    # æ‰“å°æœ€ç»ˆæŠ¥å‘Š
    print("\n========= [æœ€ç»ˆæŠ¥å‘Š] =========")
    print(final_state.get("final_report"))
    print("==============================")
